{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dff6b2d6-162e-4d09-be79-2d8da5e36e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a27592a9-70af-49c0-ad80-c4d5287c3bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data Words:\n",
      " ['natural', 'language', 'processing', 'nlp', 'enables', 'computers', 'to', 'understand', 'and', 'generate', 'human', 'language', 'it', 'is', 'a', 'crucial', 'field', 'in', 'artificial', 'intelligence', 'ai', 'that', 'deals', 'with', 'analyzing', 'and', 'representing', 'the', 'structure', 'of', 'language', 'in', 'a', 'form', 'that', 'machines', 'can', 'process', 'nlp', 'is', 'widely', 'used', 'in', 'applications', 'like', 'chatbots', 'translation', 'tools', 'and', 'voice', 'recognition', 'systems', 'continuous', 'bag', 'of', 'words', 'cbow', 'is', 'one', 'of', 'the', 'techniques', 'used', 'to', 'model', 'language', 'in', 'nlp', 'where', 'the', 'goal', 'is', 'to', 'predict', 'a', 'target', 'word', 'based', 'on', 'the', 'context', 'words', 'around', 'it', 'this', 'is', 'useful', 'for', 'building', 'word', 'embeddings', 'that', 'capture', 'semantic', 'relationships', 'between', 'words']\n"
     ]
    }
   ],
   "source": [
    "with open(\"CBOWtext.txt\",\"r\") as f:\n",
    "    doc1=f.read().lower()\n",
    "cleaned_doc1=re.sub(r\"[^a-zA-Z0-9]\",\" \",doc1).split()#targeting alphanumeric characters and also splitting the words\n",
    "print(\"Cleaned Data Words:\\n\",cleaned_doc1)#print the celaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5980cca-4bb7-4164-bd4a-2afc6df288e6",
   "metadata": {},
   "source": [
    "Bag Of Words Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43f0fefa-d7a6-4fca-8d07-8a2fbdd04ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Calculation:\n",
      "\n",
      "{'structure': 1, 'artificial': 1, 'recognition': 1, 'bag': 1, 'representing': 1, 'analyzing': 1, 'and': 3, 'deals': 1, 'between': 1, 'nlp': 3, 'around': 1, 'like': 1, 'a': 3, 'techniques': 1, 'in': 4, 'computers': 1, 'natural': 1, 'processing': 1, 'embeddings': 1, 'tools': 1, 'generate': 1, 'relationships': 1, 'of': 3, 'where': 1, 'on': 1, 'continuous': 1, 'predict': 1, 'field': 1, 'chatbots': 1, 'enables': 1, 'form': 1, 'understand': 1, 'voice': 1, 'word': 2, 'applications': 1, 'language': 4, 'can': 1, 'based': 1, 'this': 1, 'building': 1, 'useful': 1, 'one': 1, 'the': 4, 'used': 2, 'translation': 1, 'it': 2, 'human': 1, 'cbow': 1, 'goal': 1, 'is': 5, 'that': 3, 'target': 1, 'intelligence': 1, 'crucial': 1, 'context': 1, 'semantic': 1, 'capture': 1, 'words': 3, 'ai': 1, 'machines': 1, 'process': 1, 'for': 1, 'model': 1, 'to': 3, 'with': 1, 'systems': 1, 'widely': 1} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def CalculateCBOW(words):\n",
    "    return {word:words.count(word) for word in set(words)}\n",
    "\n",
    "bow1=CalculateCBOW(cleaned_doc1)\n",
    "print(\"Bag of Words Calculation:\\n\")\n",
    "print(bow1,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95285fff-a0bc-4458-b6b7-8e81ceaef749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag Of Words DataFrame:\n",
      "\n",
      "   structure  artificial  recognition  bag  representing  analyzing  and  \\\n",
      "0          1           1            1    1             1          1    3   \n",
      "\n",
      "   deals  between  nlp  ...  words  ai  machines  process  for  model  to  \\\n",
      "0      1        1    3  ...      3   1         1        1    1      1   3   \n",
      "\n",
      "   with  systems  widely  \n",
      "0     1        1       1  \n",
      "\n",
      "[1 rows x 67 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Bag Of Words DataFrame:\\n\")\n",
    "df_cbow=pd.DataFrame([bow1])\n",
    "print(df_cbow,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "430fa1ed-6e45-405c-8ea0-a813afa07fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Of Matrix [[1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 5 2 4 1 1 1 1\n",
      "  3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 3 4 1 3 1 1 1 2 1 1 1 1 1 2 3]] \n",
      "\n",
      "DataFrame:\n",
      "    ai  analyzing  and  applications  around  artificial  bag  based  between  \\\n",
      "0   1          1    3             1       1           1    1      1        1   \n",
      "\n",
      "   building  ...  translation  understand  used  useful  voice  where  widely  \\\n",
      "0         1  ...            1           1     2       1      1      1       1   \n",
      "\n",
      "   with  word  words  \n",
      "0     1     2      3  \n",
      "\n",
      "[1 rows x 66 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer=CountVectorizer()\n",
    "X=vectorizer.fit_transform([doc1])#transforms the text data into a matrix of token counts\n",
    "df_bow_sklearn=pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names_out())# Converts the sparse matrix X into a pandas DataFrame\n",
    "print(\"Array Of Matrix\",X.toarray(),\"\\n\")                            \n",
    "print(\"DataFrame:\\n\",df_bow_sklearn,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc5e2b4-1b89-4ed0-9d9e-337b13b5d040",
   "metadata": {},
   "source": [
    "#nltk word Tokenization and word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6998644-5918-4fef-9943-c9ef09080ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Mayuri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'natural': 1, 'language': 4, 'processing': 1, 'nlp': 3, 'enables': 1, 'computers': 1, 'to': 3, 'understand': 1, 'and': 3, 'generate': 1, 'human': 1, 'it': 2, 'is': 5, 'a': 3, 'crucial': 1, 'field': 1, 'in': 4, 'artificial': 1, 'intelligence': 1, 'ai': 1, 'that': 3, 'deals': 1, 'with': 1, 'analyzing': 1, 'representing': 1, 'the': 4, 'structure': 1, 'of': 3, 'form': 1, 'machines': 1, 'can': 1, 'process': 1, 'widely': 1, 'used': 2, 'applications': 1, 'like': 1, 'chatbots': 1, 'translation': 1, 'tools': 1, 'voice': 1, 'recognition': 1, 'systems': 1, 'continuous': 1, 'bag': 1, 'words': 3, 'cbow': 1, 'one': 1, 'techniques': 1, 'model': 1, 'where': 1, 'goal': 1, 'predict': 1, 'target': 1, 'word': 2, 'based': 1, 'on': 1, 'context': 1, 'around': 1, 'this': 1, 'useful': 1, 'for': 1, 'building': 1, 'embeddings': 1, 'capture': 1, 'semantic': 1, 'relationships': 1, 'between': 1}\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "dataset=[re.sub(r\"\\W\",' ',sent) for sent in nltk.sent_tokenize(doc1)]\n",
    "word2count={}\n",
    "for sentence in dataset:\n",
    "    for word in nltk.word_tokenize(sentence):\n",
    "        word2count[word]=word2count.get(word,0)+1\n",
    "print(word2count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb51bbc-1c68-4b7c-b3f5-537e20eee801",
   "metadata": {},
   "source": [
    "Prepare Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "465fb98d-da5b-4250-a008-5825d09f5418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word to Index Mapping: {'structure': 0, 'artificial': 1, 'recognition': 2, 'bag': 3, 'representing': 4, 'analyzing': 5, 'and': 6, 'deals': 7, 'between': 8, 'nlp': 9, 'around': 10, 'like': 11, 'a': 12, 'techniques': 13, 'in': 14, 'computers': 15, 'natural': 16, 'processing': 17, 'embeddings': 18, 'tools': 19, 'generate': 20, 'relationships': 21, 'of': 22, 'where': 23, 'on': 24, 'continuous': 25, 'predict': 26, 'field': 27, 'chatbots': 28, 'enables': 29, 'form': 30, 'understand': 31, 'voice': 32, 'word': 33, 'applications': 34, 'language': 35, 'can': 36, 'based': 37, 'this': 38, 'building': 39, 'useful': 40, 'one': 41, 'the': 42, 'used': 43, 'translation': 44, 'it': 45, 'human': 46, 'cbow': 47, 'goal': 48, 'is': 49, 'that': 50, 'target': 51, 'intelligence': 52, 'crucial': 53, 'context': 54, 'semantic': 55, 'capture': 56, 'words': 57, 'ai': 58, 'machines': 59, 'process': 60, 'for': 61, 'model': 62, 'to': 63, 'with': 64, 'systems': 65, 'widely': 66}\n",
      "Sample Training Data: [(['natural', 'language', 'nlp', 'enables'], 'processing'), (['language', 'processing', 'enables', 'computers'], 'nlp'), (['processing', 'nlp', 'computers', 'to'], 'enables'), (['nlp', 'enables', 'to', 'understand'], 'computers'), (['enables', 'computers', 'understand', 'and'], 'to')]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(set(cleaned_doc1))\n",
    "# Setting the embedding dimension (size of the word vectors)\n",
    "embed_dim = 10\n",
    "# Creating a word-to-index mapping (consistent naming: word_to_idx)\n",
    "word_to_idx = {word: i for i, word in enumerate(set(cleaned_doc1))}\n",
    "print(\"Word to Index Mapping:\", word_to_idx)\n",
    "embeddings = np.random.random_sample((vocab_size, embed_dim))\n",
    "data = [\n",
    "    (\n",
    "        [cleaned_doc1[i - 2], cleaned_doc1[i - 1], cleaned_doc1[i + 1], cleaned_doc1[i + 2]],  # Context words\n",
    "        cleaned_doc1[i]  # Target word\n",
    "    )\n",
    "    for i in range(2, len(cleaned_doc1) - 2)\n",
    "]\n",
    "#Printing first 5 training examples\n",
    "print(\"Sample Training Data:\", data[:5])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3921529-0030-414c-88f4-fd0229fa00b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: [(['natural', 'language', 'nlp', 'enables'], 'processing'), (['language', 'processing', 'enables', 'computers'], 'nlp'), (['processing', 'nlp', 'computers', 'to'], 'enables'), (['nlp', 'enables', 'to', 'understand'], 'computers'), (['enables', 'computers', 'understand', 'and'], 'to'), (['computers', 'to', 'and', 'generate'], 'understand'), (['to', 'understand', 'generate', 'human'], 'and'), (['understand', 'and', 'human', 'language'], 'generate'), (['and', 'generate', 'language', 'it'], 'human'), (['generate', 'human', 'it', 'is'], 'language'), (['human', 'language', 'is', 'a'], 'it'), (['language', 'it', 'a', 'crucial'], 'is'), (['it', 'is', 'crucial', 'field'], 'a'), (['is', 'a', 'field', 'in'], 'crucial'), (['a', 'crucial', 'in', 'artificial'], 'field'), (['crucial', 'field', 'artificial', 'intelligence'], 'in'), (['field', 'in', 'intelligence', 'ai'], 'artificial'), (['in', 'artificial', 'ai', 'that'], 'intelligence'), (['artificial', 'intelligence', 'that', 'deals'], 'ai'), (['intelligence', 'ai', 'deals', 'with'], 'that'), (['ai', 'that', 'with', 'analyzing'], 'deals'), (['that', 'deals', 'analyzing', 'and'], 'with'), (['deals', 'with', 'and', 'representing'], 'analyzing'), (['with', 'analyzing', 'representing', 'the'], 'and'), (['analyzing', 'and', 'the', 'structure'], 'representing'), (['and', 'representing', 'structure', 'of'], 'the'), (['representing', 'the', 'of', 'language'], 'structure'), (['the', 'structure', 'language', 'in'], 'of'), (['structure', 'of', 'in', 'a'], 'language'), (['of', 'language', 'a', 'form'], 'in'), (['language', 'in', 'form', 'that'], 'a'), (['in', 'a', 'that', 'machines'], 'form'), (['a', 'form', 'machines', 'can'], 'that'), (['form', 'that', 'can', 'process'], 'machines'), (['that', 'machines', 'process', 'nlp'], 'can'), (['machines', 'can', 'nlp', 'is'], 'process'), (['can', 'process', 'is', 'widely'], 'nlp'), (['process', 'nlp', 'widely', 'used'], 'is'), (['nlp', 'is', 'used', 'in'], 'widely'), (['is', 'widely', 'in', 'applications'], 'used'), (['widely', 'used', 'applications', 'like'], 'in'), (['used', 'in', 'like', 'chatbots'], 'applications'), (['in', 'applications', 'chatbots', 'translation'], 'like'), (['applications', 'like', 'translation', 'tools'], 'chatbots'), (['like', 'chatbots', 'tools', 'and'], 'translation'), (['chatbots', 'translation', 'and', 'voice'], 'tools'), (['translation', 'tools', 'voice', 'recognition'], 'and'), (['tools', 'and', 'recognition', 'systems'], 'voice'), (['and', 'voice', 'systems', 'continuous'], 'recognition'), (['voice', 'recognition', 'continuous', 'bag'], 'systems'), (['recognition', 'systems', 'bag', 'of'], 'continuous'), (['systems', 'continuous', 'of', 'words'], 'bag'), (['continuous', 'bag', 'words', 'cbow'], 'of'), (['bag', 'of', 'cbow', 'is'], 'words'), (['of', 'words', 'is', 'one'], 'cbow'), (['words', 'cbow', 'one', 'of'], 'is'), (['cbow', 'is', 'of', 'the'], 'one'), (['is', 'one', 'the', 'techniques'], 'of'), (['one', 'of', 'techniques', 'used'], 'the'), (['of', 'the', 'used', 'to'], 'techniques'), (['the', 'techniques', 'to', 'model'], 'used'), (['techniques', 'used', 'model', 'language'], 'to'), (['used', 'to', 'language', 'in'], 'model'), (['to', 'model', 'in', 'nlp'], 'language'), (['model', 'language', 'nlp', 'where'], 'in'), (['language', 'in', 'where', 'the'], 'nlp'), (['in', 'nlp', 'the', 'goal'], 'where'), (['nlp', 'where', 'goal', 'is'], 'the'), (['where', 'the', 'is', 'to'], 'goal'), (['the', 'goal', 'to', 'predict'], 'is'), (['goal', 'is', 'predict', 'a'], 'to'), (['is', 'to', 'a', 'target'], 'predict'), (['to', 'predict', 'target', 'word'], 'a'), (['predict', 'a', 'word', 'based'], 'target'), (['a', 'target', 'based', 'on'], 'word'), (['target', 'word', 'on', 'the'], 'based'), (['word', 'based', 'the', 'context'], 'on'), (['based', 'on', 'context', 'words'], 'the'), (['on', 'the', 'words', 'around'], 'context'), (['the', 'context', 'around', 'it'], 'words'), (['context', 'words', 'it', 'this'], 'around'), (['words', 'around', 'this', 'is'], 'it'), (['around', 'it', 'is', 'useful'], 'this'), (['it', 'this', 'useful', 'for'], 'is'), (['this', 'is', 'for', 'building'], 'useful'), (['is', 'useful', 'building', 'word'], 'for'), (['useful', 'for', 'word', 'embeddings'], 'building'), (['for', 'building', 'embeddings', 'that'], 'word'), (['building', 'word', 'that', 'capture'], 'embeddings'), (['word', 'embeddings', 'capture', 'semantic'], 'that'), (['embeddings', 'that', 'semantic', 'relationships'], 'capture'), (['that', 'capture', 'relationships', 'between'], 'semantic'), (['capture', 'semantic', 'between', 'words'], 'relationships')]\n",
      "\n",
      "\n",
      "Embeddings: [[0.44316374 0.36775526 0.58234922 0.26531685 0.43615886 0.86535551\n",
      "  0.9581649  0.44137204 0.66381268 0.51519756]\n",
      " [0.06257792 0.03834931 0.14601599 0.8318137  0.20696646 0.88838841\n",
      "  0.88761947 0.6147095  0.59379382 0.79728029]\n",
      " [0.22633821 0.6252029  0.64109072 0.3755791  0.81369001 0.3178004\n",
      "  0.4928132  0.75642647 0.71073995 0.30186173]\n",
      " [0.40268841 0.98597593 0.6619606  0.97345686 0.97638932 0.76890576\n",
      "  0.6014407  0.9439815  0.58227345 0.61451259]\n",
      " [0.44819738 0.60186563 0.41610272 0.6007978  0.61420696 0.77326781\n",
      "  0.72884191 0.13779829 0.73480994 0.01024205]\n",
      " [0.91352523 0.5954169  0.78474564 0.66578946 0.65879315 0.65175136\n",
      "  0.96350041 0.48578489 0.54265927 0.3771068 ]\n",
      " [0.24095728 0.38836026 0.52287491 0.4634315  0.51171614 0.10821509\n",
      "  0.25223736 0.05209392 0.31015658 0.21596212]\n",
      " [0.07621016 0.7200264  0.58091822 0.40891444 0.72757325 0.27600335\n",
      "  0.77320384 0.19906749 0.81684624 0.07691946]\n",
      " [0.88115843 0.33280133 0.05842587 0.72982903 0.43823289 0.70151711\n",
      "  0.28922592 0.86313691 0.37430627 0.90298722]\n",
      " [0.8165662  0.39230311 0.47645117 0.1236822  0.34366188 0.00679605\n",
      "  0.8150852  0.66336568 0.84568294 0.49271462]\n",
      " [0.38951884 0.39256671 0.63989281 0.57826812 0.5963975  0.2732181\n",
      "  0.53907691 0.9640984  0.77543741 0.98881852]\n",
      " [0.49021334 0.35730669 0.76405149 0.13915017 0.4940878  0.79388956\n",
      "  0.46702298 0.76213263 0.22377393 0.57243377]\n",
      " [0.58640913 0.7365972  0.8400026  0.60516111 0.18239829 0.35727937\n",
      "  0.31727777 0.45927003 0.41659949 0.16955552]\n",
      " [0.40122493 0.20961339 0.34072805 0.70019427 0.00134184 0.95227712\n",
      "  0.58826189 0.36335285 0.88290563 0.8441567 ]\n",
      " [0.96127249 0.96613308 0.45737699 0.12697206 0.55764354 0.42120928\n",
      "  0.9251087  0.69558068 0.86509136 0.94473858]\n",
      " [0.03149376 0.93147197 0.76819431 0.27264081 0.02185013 0.32533134\n",
      "  0.1835554  0.51185485 0.08014214 0.6687945 ]\n",
      " [0.1258209  0.86635501 0.73436847 0.23473219 0.11647281 0.46668885\n",
      "  0.52049604 0.79121122 0.21111261 0.31615996]\n",
      " [0.67978429 0.2498493  0.39413107 0.26486962 0.11166794 0.28860843\n",
      "  0.45406289 0.20883083 0.44116254 0.82176393]\n",
      " [0.41172416 0.20687137 0.56074722 0.8147384  0.00229581 0.01524726\n",
      "  0.17024008 0.15808899 0.90231759 0.04789585]\n",
      " [0.86878215 0.22719876 0.35572704 0.25869286 0.28472255 0.72752339\n",
      "  0.71987375 0.8875315  0.45371229 0.02268212]\n",
      " [0.24088357 0.5755522  0.91546429 0.39541685 0.58807112 0.10682976\n",
      "  0.53667665 0.08998968 0.31994299 0.64708729]\n",
      " [0.40687242 0.45453581 0.50827275 0.17892593 0.51046307 0.78562181\n",
      "  0.58640662 0.4470608  0.8496365  0.58242968]\n",
      " [0.05729167 0.08574873 0.18068344 0.84959691 0.28868661 0.36747472\n",
      "  0.91907879 0.3990678  0.63283636 0.29633305]\n",
      " [0.16011702 0.0407331  0.98850614 0.48432208 0.07811496 0.7634621\n",
      "  0.85378544 0.57791584 0.5473241  0.85156558]\n",
      " [0.58401842 0.02605027 0.44194599 0.56626589 0.65891083 0.48474757\n",
      "  0.57160462 0.3229424  0.84291331 0.2592677 ]\n",
      " [0.74616893 0.39290996 0.39026944 0.80333823 0.04977479 0.08385114\n",
      "  0.8563132  0.30968715 0.39573088 0.95925377]\n",
      " [0.60186136 0.46666468 0.76079235 0.24612592 0.22625985 0.16255464\n",
      "  0.34448807 0.52943637 0.35126896 0.13631537]\n",
      " [0.75268882 0.46216063 0.43265776 0.89467942 0.08904399 0.88505543\n",
      "  0.5011909  0.64960849 0.3274897  0.55868259]\n",
      " [0.05765894 0.82236468 0.01461929 0.46881223 0.74575575 0.569264\n",
      "  0.14202851 0.62340124 0.70210761 0.80911206]\n",
      " [0.61130765 0.44187568 0.61580491 0.5733644  0.24754238 0.75419416\n",
      "  0.50127902 0.1749153  0.62833846 0.26837226]\n",
      " [0.56836529 0.92871659 0.27960289 0.38749126 0.79328108 0.01839226\n",
      "  0.10878627 0.67700552 0.50102981 0.82795421]\n",
      " [0.98475101 0.3635547  0.69564131 0.19726827 0.30115178 0.54480505\n",
      "  0.41365046 0.57454299 0.16207879 0.67549044]\n",
      " [0.44912417 0.90286878 0.25098727 0.23705184 0.17239444 0.84629904\n",
      "  0.96736458 0.51960813 0.96963093 0.87696903]\n",
      " [0.01516061 0.6612627  0.36745517 0.96694839 0.82725764 0.50681157\n",
      "  0.52060357 0.82307346 0.2855053  0.63142558]\n",
      " [0.23045211 0.29490279 0.74323511 0.78727291 0.08032955 0.15101348\n",
      "  0.38072418 0.41131754 0.32864906 0.19733925]\n",
      " [0.11709029 0.73047678 0.74694765 0.51137618 0.10095921 0.05808518\n",
      "  0.34590847 0.25734519 0.70047917 0.30181615]\n",
      " [0.45587204 0.10516008 0.67746563 0.07813847 0.86960508 0.58540348\n",
      "  0.49750411 0.14466369 0.03380942 0.16027495]\n",
      " [0.10324729 0.80129858 0.84569583 0.95715223 0.59535312 0.59527579\n",
      "  0.51391983 0.96328909 0.78084774 0.26395961]\n",
      " [0.03035623 0.4438554  0.77810334 0.33818395 0.96384765 0.32925067\n",
      "  0.22185141 0.28536899 0.27888177 0.80613658]\n",
      " [0.32329779 0.58645683 0.58538749 0.96649946 0.94047211 0.76543244\n",
      "  0.66045508 0.55144194 0.55652246 0.15312069]\n",
      " [0.34390611 0.5534624  0.90105351 0.03518725 0.36576458 0.20250496\n",
      "  0.80012806 0.25023476 0.02768593 0.89462784]\n",
      " [0.71639156 0.65697494 0.49437074 0.57169608 0.49465885 0.00145217\n",
      "  0.46108345 0.97687663 0.17266288 0.62000943]\n",
      " [0.68724539 0.77045984 0.91698145 0.41826144 0.41017112 0.22000872\n",
      "  0.65218587 0.32633182 0.24202293 0.30299905]\n",
      " [0.23223651 0.70836778 0.84703249 0.90604792 0.88681183 0.14544358\n",
      "  0.92051962 0.56753205 0.81925553 0.4960329 ]\n",
      " [0.78036322 0.97417331 0.64385174 0.88014407 0.7693484  0.06994276\n",
      "  0.35658278 0.88096806 0.50813703 0.46548733]\n",
      " [0.00133777 0.59636278 0.18216352 0.89174794 0.76868309 0.36090048\n",
      "  0.83365916 0.95491295 0.35291421 0.56463172]\n",
      " [0.21717523 0.4996759  0.93985664 0.32036609 0.85729045 0.35625356\n",
      "  0.79045443 0.49096405 0.64325939 0.705346  ]\n",
      " [0.39800299 0.8151404  0.36101605 0.70120045 0.08917726 0.90994775\n",
      "  0.55513026 0.64051507 0.40720638 0.39950812]\n",
      " [0.72931743 0.8373627  0.03466122 0.9171003  0.45626259 0.08636287\n",
      "  0.08835806 0.39446839 0.23928234 0.91810363]\n",
      " [0.46176029 0.51465919 0.55966879 0.63196777 0.82897519 0.92727983\n",
      "  0.81342217 0.26918668 0.00472967 0.62493441]\n",
      " [0.8552219  0.92215682 0.73928616 0.45933877 0.15259927 0.86485373\n",
      "  0.92762006 0.38690531 0.79865465 0.91007655]\n",
      " [0.65350248 0.67147246 0.16547936 0.41356589 0.85136968 0.26075318\n",
      "  0.18137274 0.59729872 0.95208883 0.85114261]\n",
      " [0.65267388 0.08908734 0.18770933 0.25238038 0.64989246 0.30779271\n",
      "  0.9993321  0.4246794  0.98770515 0.50241976]\n",
      " [0.79240874 0.56435972 0.29188608 0.2916493  0.73466925 0.45300752\n",
      "  0.56053279 0.0597798  0.13435075 0.66171129]\n",
      " [0.1914719  0.64533951 0.43746476 0.83093782 0.36542922 0.20375909\n",
      "  0.87971928 0.85617807 0.92913083 0.78290672]\n",
      " [0.90026489 0.47271547 0.38962724 0.45228584 0.15895584 0.48109216\n",
      "  0.66305713 0.41213044 0.93180881 0.32829173]\n",
      " [0.63356189 0.19783923 0.44737281 0.05782155 0.87054848 0.71189003\n",
      "  0.03800593 0.21940119 0.58411572 0.38627129]\n",
      " [0.16678815 0.86621183 0.39337716 0.7436524  0.87691782 0.69943811\n",
      "  0.6855394  0.84020199 0.30110768 0.10414523]\n",
      " [0.04830387 0.86808388 0.63490749 0.92261958 0.73542178 0.46597416\n",
      "  0.42886026 0.78396019 0.98910276 0.55316441]\n",
      " [0.5848548  0.75452122 0.47395424 0.37092863 0.3891428  0.62204929\n",
      "  0.66037224 0.30850927 0.33490084 0.71859282]\n",
      " [0.85319281 0.9756054  0.21674387 0.03520055 0.70911502 0.37142422\n",
      "  0.42281616 0.02799153 0.39744654 0.02831103]\n",
      " [0.64748828 0.63579902 0.45771048 0.92727019 0.13296483 0.09565634\n",
      "  0.30243306 0.67941316 0.67595131 0.9116696 ]\n",
      " [0.23585857 0.15202774 0.32136306 0.11351971 0.40676792 0.37747746\n",
      "  0.05378881 0.23132151 0.5681962  0.32108325]\n",
      " [0.87054118 0.7874864  0.50080544 0.09409731 0.54372119 0.29277322\n",
      "  0.29538007 0.16895988 0.19292707 0.32883883]\n",
      " [0.35463255 0.36582727 0.19968205 0.44859086 0.41165148 0.35846403\n",
      "  0.32887537 0.57420631 0.00466854 0.66613072]\n",
      " [0.58567209 0.20140295 0.8030073  0.58451562 0.30680259 0.74857899\n",
      "  0.20488439 0.02976907 0.29500572 0.08607343]\n",
      " [0.74003578 0.00258318 0.58878418 0.95036536 0.80995914 0.17701313\n",
      "  0.27899808 0.18637045 0.96875836 0.92032051]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Data:\",data)\n",
    "print(\"\\n\\nEmbeddings:\",embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ad91dc-c418-409e-afe5-ded142b849f5",
   "metadata": {},
   "source": [
    "Converting Words into Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d6b5857-8ce3-4f6f-9a37-1c634f56363e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Indices (first 5): [[16, 35, 9, 29], [35, 17, 29, 15], [17, 9, 15, 63], [9, 29, 63, 31], [29, 15, 31, 6]]\n",
      "Target Indices (first 5): [17, 9, 29, 15, 63]\n"
     ]
    }
   ],
   "source": [
    "context_indices = [\n",
    "    [word_to_idx[word] for word in context]  # Convert each context word to its index\n",
    "    for context, target in data\n",
    "]\n",
    "\n",
    "# Convert target words to their indices\n",
    "target_indices = [\n",
    "    word_to_idx[target]  # Convert target word to its index\n",
    "    for context, target in data\n",
    "]\n",
    "\n",
    "print(\"Context Indices (first 5):\", context_indices[:5])\n",
    "print(\"Target Indices (first 5):\", target_indices[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353b4c8c-a3f7-42fd-80d1-6854276c30f8",
   "metadata": {},
   "source": [
    "Preparing model and printing Predicted Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f4cf04f-2db3-46a7-90d6-24fafc1831c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,Dense,Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ddb027-e6b0-45b7-9590-d1a9e230378a",
   "metadata": {},
   "source": [
    "Covert to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95c16340-ebc3-46bd-8953-9e58c4780018",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.array(context_indices)\n",
    "y_train=np.array(target_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c4c9a2-e092-4dc7-9faf-175f2ef6f384",
   "metadata": {},
   "source": [
    "Define CBOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a500b6b-05b5-4ffa-9356-068d854ce653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.0000e+00 - loss: 4.2047\n",
      "Epoch 2/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0488 - loss: 4.1959 \n",
      "Epoch 3/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0860 - loss: 4.1911 \n",
      "Epoch 4/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0821 - loss: 4.1854 \n",
      "Epoch 5/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1031 - loss: 4.1788 \n",
      "Epoch 6/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1216 - loss: 4.1719 \n",
      "Epoch 7/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1534 - loss: 4.1694 \n",
      "Epoch 8/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1495 - loss: 4.1609 \n",
      "Epoch 9/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1827 - loss: 4.1566 \n",
      "Epoch 10/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2692 - loss: 4.1466 \n",
      "Epoch 11/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2345 - loss: 4.1399 \n",
      "Epoch 12/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3835 - loss: 4.1356 \n",
      "Epoch 13/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4494 - loss: 4.1263 \n",
      "Epoch 14/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4880 - loss: 4.1217 \n",
      "Epoch 15/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4997 - loss: 4.1133 \n",
      "Epoch 16/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5042 - loss: 4.1071 \n",
      "Epoch 17/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5501 - loss: 4.0976 \n",
      "Epoch 18/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5389 - loss: 4.0903 \n",
      "Epoch 19/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5271 - loss: 4.0837 \n",
      "Epoch 20/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5545 - loss: 4.0736 \n",
      "Epoch 21/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6082 - loss: 4.0636 \n",
      "Epoch 22/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6009 - loss: 4.0561 \n",
      "Epoch 23/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6126 - loss: 4.0458 \n",
      "Epoch 24/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6654 - loss: 4.0335 \n",
      "Epoch 25/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6551 - loss: 4.0302 \n",
      "Epoch 26/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6854 - loss: 4.0120 \n",
      "Epoch 27/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7025 - loss: 4.0036 \n",
      "Epoch 28/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7421 - loss: 3.9857 \n",
      "Epoch 29/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7513 - loss: 3.9726 \n",
      "Epoch 30/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7763 - loss: 3.9570 \n",
      "Epoch 31/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7909 - loss: 3.9511 \n",
      "Epoch 32/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7704 - loss: 3.9392 \n",
      "Epoch 33/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8398 - loss: 3.9238 \n",
      "Epoch 34/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 3.9015 \n",
      "Epoch 35/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8593 - loss: 3.8923  \n",
      "Epoch 36/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7968 - loss: 3.8743 \n",
      "Epoch 37/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8334 - loss: 3.8670 \n",
      "Epoch 38/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8490 - loss: 3.8419 \n",
      "Epoch 39/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8598 - loss: 3.8256 \n",
      "Epoch 40/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8940 - loss: 3.7939 \n",
      "Epoch 41/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8432 - loss: 3.7941 \n",
      "Epoch 42/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9189 - loss: 3.7501 \n",
      "Epoch 43/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8969 - loss: 3.7367 \n",
      "Epoch 44/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9008 - loss: 3.7185 \n",
      "Epoch 45/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8906 - loss: 3.6983 \n",
      "Epoch 46/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9218 - loss: 3.6737 \n",
      "Epoch 47/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8984 - loss: 3.6511 \n",
      "Epoch 48/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9140 - loss: 3.6381 \n",
      "Epoch 49/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9140 - loss: 3.6067 \n",
      "Epoch 50/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9062 - loss: 3.5832 \n",
      "Epoch 51/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9218 - loss: 3.5518 \n",
      "Epoch 52/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9272 - loss: 3.5255 \n",
      "Epoch 53/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9116 - loss: 3.5064 \n",
      "Epoch 54/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9326 - loss: 3.4637 \n",
      "Epoch 55/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9209 - loss: 3.4408 \n",
      "Epoch 56/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9326 - loss: 3.4152 \n",
      "Epoch 57/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9170 - loss: 3.3915  \n",
      "Epoch 58/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9536 - loss: 3.3372 \n",
      "Epoch 59/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9536 - loss: 3.3169 \n",
      "Epoch 60/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9536 - loss: 3.2932 \n",
      "Epoch 61/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9458 - loss: 3.2511 \n",
      "Epoch 62/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9419 - loss: 3.2155 \n",
      "Epoch 63/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9590 - loss: 3.1755 \n",
      "Epoch 64/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9668 - loss: 3.1497  \n",
      "Epoch 65/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9590 - loss: 3.1211 \n",
      "Epoch 66/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9629 - loss: 3.0725 \n",
      "Epoch 67/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9590 - loss: 3.0392 \n",
      "Epoch 68/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9551 - loss: 3.0071 \n",
      "Epoch 69/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9629 - loss: 2.9747 \n",
      "Epoch 70/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9590 - loss: 2.9274 \n",
      "Epoch 71/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9512 - loss: 2.8830 \n",
      "Epoch 72/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9394 - loss: 2.8662 \n",
      "Epoch 73/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9800 - loss: 2.8132 \n",
      "Epoch 74/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9853 - loss: 2.7689 \n",
      "Epoch 75/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9892 - loss: 2.6994 \n",
      "Epoch 76/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9736 - loss: 2.6629\n",
      "Epoch 77/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9829 - loss: 2.6288 \n",
      "Epoch 78/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9907 - loss: 2.5916 \n",
      "Epoch 79/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 2.5454 \n",
      "Epoch 80/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9907 - loss: 2.4805 \n",
      "Epoch 81/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9829 - loss: 2.4559 \n",
      "Epoch 82/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 2.4042 \n",
      "Epoch 83/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9829 - loss: 2.3770 \n",
      "Epoch 84/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9907 - loss: 2.3134 \n",
      "Epoch 85/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9829 - loss: 2.3041 \n",
      "Epoch 86/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9907 - loss: 2.2205 \n",
      "Epoch 87/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 2.1933 \n",
      "Epoch 88/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 2.1363 \n",
      "Epoch 89/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9907 - loss: 2.0691 \n",
      "Epoch 90/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9907 - loss: 2.0479 \n",
      "Epoch 91/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 2.0318 \n",
      "Epoch 92/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9907 - loss: 1.9590 \n",
      "Epoch 93/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9946 - loss: 1.9057 \n",
      "Epoch 94/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 1.8888 \n",
      "Epoch 95/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9907 - loss: 1.8105 \n",
      "Epoch 96/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9829 - loss: 1.7687 \n",
      "Epoch 97/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 1.7419 \n",
      "Epoch 98/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9946 - loss: 1.6847 \n",
      "Epoch 99/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9829 - loss: 1.6667 \n",
      "Epoch 100/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 1.5593 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2600f4a4210>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size,output_dim=embed_dim,input_length=4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(vocab_size,activation='softmax'))\n",
    "#Compile the Model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#Train the Model\n",
    "model.fit(x_train,y_train,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e3e6327-f91e-4af8-ac9a-5463718b1a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_context=['artificial','recognition','analyzing','generate']\n",
    "example_context_indices = np.array([[word_to_indx[word] for word in example_context]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d74df480-2bc0-4798-ad6d-4ca7fec74eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Predicted Word:ai\n"
     ]
    }
   ],
   "source": [
    "predicted=model.predict(example_context_indices)\n",
    "predicted_word_indx=np.argmax(predicted,axis=1)\n",
    "predicted_word=list(word_to_indx.keys())[predicted_word_indx[0]]\n",
    "print(f\"Predicted Word:{predicted_word}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
